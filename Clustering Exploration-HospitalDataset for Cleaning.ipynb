{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring representative tuples by clustering the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "from sklearn.cluster import KMeans, Birch\n",
    "from gensim.models.wrappers import FastText\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform clustering and return the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastTextModelPath = 'EmbeddingsFastText.w2v'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClusterCentersWithKMeans(model, numberOfClusters):\n",
    "    # Get the word vectors of the model\n",
    "    word_vectors = model.wv.syn0\n",
    "    n_words = word_vectors.shape[0]\n",
    "    vec_size = word_vectors.shape[1]\n",
    "    print(\"Number of words = {0}, vector size = {1}\".format(n_words, vec_size))\n",
    "\n",
    "    # Cluster using KMeans\n",
    "    start = time.time()\n",
    "    print(\"Clustering ... \", end=\"\", flush=True)\n",
    "    kmeans = KMeans(n_clusters=numberOfClusters, n_jobs=-1, random_state=0)\n",
    "    idx = kmeans.fit_predict(word_vectors)\n",
    "    print(\"Finished clustering in {:.2f} sec.\".format(time.time() - start), flush=True)\n",
    "\n",
    "    # Return cluster centers\n",
    "    return kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the closest vector to each of the cluster centers\n",
    "We'll pass the number of cluster centers as an argument. This can be thought of as a drill down equivalent. Greater the number of cluster centers, more detailed will be the resulting results returned. \n",
    "\n",
    "Number of clusters chosen is 3 by default. This can be overriden, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClosestWordEmbedding(modelPath, numberOfClusters = 15):\n",
    "    # Load the model\n",
    "    start = time.time()\n",
    "    model = KeyedVectors.load(modelPath)\n",
    "    print(\"Finished loading model in {:.2f} sec.\".format(time.time() - start), flush=True)\n",
    "    \n",
    "    clusterCenters = getClusterCentersWithKMeans(model, numberOfClusters)\n",
    "    \n",
    "    # Create an empty numpy array of size equal to cluster centers to store the closest words\n",
    "    closestWords = []\n",
    "    \n",
    "    \n",
    "    # Get the closest word for each of the cluster centers\n",
    "    #for clusterCenter in clusterCenters:\n",
    "    closestWords.append(model.similar_by_vector('3x640'))\n",
    "            #closestWords.append(model.similar_by_vector(clusterCenter))\n",
    "    \n",
    "    return closestWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getClosestWordEmbedding(word2VecModelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model in 0.10 sec.\n",
      "Number of words = 777, vector size = 100\n",
      "Clustering ... Finished clustering in 0.33 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('MORGAN', 0.9681735038757324),\n",
       "  ('HARTSELLE', 0.9302594661712646),\n",
       "  ('35640', 0.858690619468689),\n",
       "  ('2567736511', 0.7711230516433716),\n",
       "  ('DECATUR', 0.7628130316734314),\n",
       "  ('201 PINE STREET NORTHWEST', 0.7309060096740723),\n",
       "  ('HARTSELLE MEDICAL CENTER', 0.48642146587371826),\n",
       "  ('35609', 0.47125619649887085),\n",
       "  ('ETOWAH', 0.4642176032066345),\n",
       "  ('1201 7TH STREET SE', 0.4625547528266907)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getClosestWordEmbedding(fastTextModelPath, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
